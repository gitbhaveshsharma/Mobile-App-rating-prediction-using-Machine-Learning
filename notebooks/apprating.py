# -*- coding: utf-8 -*-
"""AppRating.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hGM8RSPNN7rLOS2DNNJeea7WeitZ_ZY8
"""

import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
import seaborn as sns
from sklearn.impute import KNNImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor

df = pd.read_csv("/content/googleplaystore.csv")
df.head()

df.info()

df = df.rename(columns=str.lower)

df.columns

"""#Are there duplicate values?"""

print('Duplicate rows: ', df.duplicated().sum())
df.drop_duplicates(inplace = True)
print('Duplicate rows after drop: ', df.duplicated().sum())

"""As we need work on some features like "Reviews," "Size," "Installs," and "Price". let's convert and clean string-based numerical features like "Reviews," "Size," "Installs," and "Price" into appropriate numerical formats.

# **Reviwes**

**Reviwes cleaning and converting**
"""

df['reviews'].unique()

df['reviews'].isnull().sum()

print(df['reviews'].dtype)

"""Here is some problame col type is object, wheater it should be numeric(float, int) or non-numeric(str)

Let's Check, how much row is numeric or non-numeric?
"""

print('Number of non numeric reviews :', len(df) - df.reviews.str.isnumeric().sum())

"""let's anlyze the non numeric row of the reviwes"""

df[pd.to_numeric(df.reviews, errors='coerce').isna()]

df.head(1)

df.shape

"""**The data at row 9300 is incorrect. The values in all of the columns are wrong. The correct data for row 9300 is look like as follows:**


The following changes need to be made to the incorrect data:

* The app name should be "Photo Editor & Candy Camera & Grid & ScrapBook".
* The category should be "ART_AND_DESIGN".
* The rating should be "4.1".
* The number of reviews should be "159".
* The size should be "19M".
* The number of installs should be "10,000+".
* The type should be "Free".
* The price should be "0".
* The content rating should be "Everyone".
* The genres should be "Art & Design".
* The last updated date should be "January 7, 2018".
* The current version should be "1.0.0".
* The minimum Android version should be "4.0.3 and up".

It should be look like above list but the data is looking much diffrent then other row so we need to remove this row.
"""

df= df.drop(10472)
df = df.reset_index(drop=True)

df.shape

"""After removing the the non-numeric value."""

print('Number of non numeric reviews :', len(df) - df.reviews.str.isnumeric().sum())

"""Now lets convert reviwes column into **int64** data type"""

df['reviews'] = df['reviews'].astype('Int64')

print(df['reviews'].dtype)

"""# **Size**

**Size cleaning and converting**
"""

df['size']

"""We observe that various applications display the letter 'M' as an abbreviation for megabytes (MB). Additionally, there is a size indicator labeled as 'Varies with device.' Our objective is to employ regular expressions to explore if there are any alternative non-numeric size representations."""

df[~df['size'].str.contains('\d+M', regex=True, na=False)].head(5)

"""Let's investigate if there are any other characters or strings used to represent sizes besides 'k', 'M', and 'Varies with device'.

Upon examining the available data, we observe that certain entries display 'Varies with device' as their size indication. Additionally, a few apps specify their size in kilobytes (KB), denoted by the letter 'k'.

Now, we will explore whether there are any alternative characters or strings used to represent app sizes.
"""

df[df['size'].str.contains('[^kMVaries with device]$', regex=True, na=False)].head()

"""Okay, the sizes can be expressed in **KB (k)**, **MB** **(M)**, or they may vary depending on the device.


We will assign the label 'NaN' to the size values that correspond to **"Varies with device."**
"""

df['size'] = df['size'].replace("Varies with device",np.nan)

df['size']

"""Next, let's proceed with the conversion of the sizes to kilobytes (KB) and megabytes (MB)."""

size = []
for i in df['size']:
    if pd.isna(i):
        size.append('NaN')
    elif isinstance(i, str) and i[-1] == 'k':
        size.append(float(i[:-1]) / 1000)
    elif isinstance(i, str) and i[-1] == 'M':
        size.append(float(i[:-1]) * 1000)
    else:
        size.append(float(i))

df['size'] = size
df['size'] = df['size'].astype(float)

df['size'].dtype

"""# **Install**

**Install cleaning and converting**
"""

df['installs']

df['installs'].isnull().sum()

"""We will remove the **'+'** symbol from the rows and add it to the feature name."""

df['installs'] = df['installs'].str.replace(",", "",regex=True).str.replace("+", "",regex=True)

df.head()

"""Now lets convert install column into **float** data type"""

df['installs']=pd.to_numeric(df['installs'])
df['installs'].unique()

"""# **Price**

**Install cleaning and converting**
"""

df['price'].head()

df['price'].unique()

df['price'].isnull().sum()

"""There are no missing values in the price column

"Remove the ***'$' ***symbol from the price and convert type into float:
"""

df['price'] = df['price'].astype(str).str.replace('$', '', regex=True).astype(float)

# df['price'] = pd.to_numeric(df['price'])

df['price'].dtype

df['price'].value_counts()

df.isnull().sum()

"""**There are some rows with missing values for rating and size. We can impute these quantites by KNNImputer later.**"""

# df.dropna(inplace=True)
# df.isnull().sum()

df['current ver']

df['current ver'] = df['current ver'].replace('Varies with device', 'NaN', regex=True)

df['current ver'].value_counts()

df['current ver']=df['current ver'].str.extract(r'^(\d+).', ).astype(float)

df.info()

df['android ver']=df['android ver'].replace('and up', '', regex=True)

df['android ver'].value_counts()

df['android ver'] = df['android ver'].replace('Varies with device', np.nan, regex=True)
df['android ver'] = df['android ver'].replace('W', np.nan, regex=True)
df=df.loc[df['android ver'].str.contains(r'-') == False]

df['android ver']=df['android ver'].str.strip()

df['android ver'].value_counts()

df['android ver'] = df['android ver'].apply(lambda x: x[:3]).astype(float)

df['last updated Year']=pd.to_datetime(df['last updated'])

df['last updated Year']=df['last updated Year'].dt.year

"""# **Exploratory Data Analysis**"""

def num_plots(df, column, title, xaxis_title):
    fig = px.histogram(df, x=column, nbins=60, title=title)
    fig.update_layout(xaxis_title=xaxis_title, bargap=0.2)
    fig.show()

df['rating'].describe()

num_plots(df, 'rating', 'App rating distribution', 'Rating')

counts = df['type'].value_counts().reset_index()

counts.columns = ['type', 'count']


fig = px.bar(counts, x='type', y='count', title='Paid vs Free apps', color='type')
fig.update_layout(xaxis_title='App type')
fig.show()

counts = df['content rating'].value_counts().reset_index()

counts.columns = ['content rating', 'count']

fig = px.bar(counts, x='content rating', y='count', title='Paid vs Free apps', color='content rating')
fig.update_layout(xaxis_tickangle=-60)
fig.show()

fig = px.box(df, x='content rating', y='rating', title='Content rating vs rating', color='content rating')
fig.show()

fig = px.box(df, x='content rating', y='installs', color='type', title='Installs per content rating by type')
fig.update_traces(boxmean=True)
fig.update_layout(yaxis_type='log')
fig.show()

df['genres'].value_counts()

corr_matrix = df.corr()

print(corr_matrix)

plt.figure(figsize=(6, 6))
sns.heatmap(corr_matrix, annot=True, cmap='Greens')
plt.title('Correlation Matrix')
plt.show()

fig = px.scatter(df, x='price', y='rating', trendline='ols', title='Price VS Rating')
fig.update_layout(showlegend=False)
fig.show()

fig = px.box(df, x='category', y='rating', color='type', title='Rating vs Category')
fig.update_layout(xaxis_tickangle=-90)
fig.show()

df['size']

fig = px.scatter(df, x='rating', y='size', trendline='ols', title='Rating vs Size')
fig.show()

df.info()

df1=df.copy()



df=df.drop(['app','last updated'], axis=1)

df['last updated']=df1['last updated']

df.head()

df=df.drop(['last updated'], axis=1)

df.describe()

"""**Categorical features Encoding**

To replace the values 'Free' and 'Paid' with 0 and 1, respectively, in the 'price' column
"""

df['type'] = df['type'].replace({'Free':0, "Paid":1})

#df_after_all=df.copy()

data=df_after_all.copy()

data.info()

"""Regarding the encoding of the 'Content Rating' and 'Genres' columns, we will utilize a label encoder instead of one-hot encoding (OHE) to avoid generating an excessive number of columns."""

en = LabelEncoder()
allCcols = ['category', 'content rating', 'genres']

for col in allCcols:
    data[col] = en.fit_transform(data[col])

data.info()

"""**To address the missing values in the 'rating' and 'size' columns, we can utilize the KNNImputer for imputation.**"""

imputer = KNNImputer(n_neighbors=3)
data = pd.DataFrame(imputer.fit_transform(data),columns = data.columns)

data.isnull().sum()

data.info()

X=data.drop('rating', axis = 1).values

y=data['rating'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

scaler = MinMaxScaler()

scaler.fit(X_train)

X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

rf = RandomForestRegressor()

rf.fit(X_train,y_train)

y_pred_rf = rf.predict(X_test)

mse_rf = mean_squared_error(y_test, y_pred_rf)
print("RMSE using RF: ", np.sqrt(mse_rf))

"""# **XGBot**"""

xgb = XGBRegressor(n_estimators=2000, learning_rate=0.01)
xgb.fit(X_train, y_train)
y_pred_xgb = xgb.predict(X_test)
mse_xgb = mean_squared_error(y_pred_xgb, y_test)

print(r"RMSE with RF: {:.3f}".format(np.sqrt(mse_rf)))
print(r"RMSE with XGBoost: {:.3f}".format(np.sqrt(mse_xgb)))

"""In your case, you mentioned two models: Random Forest (RF) and XGBoost. Both models have achieved similar RMSE values: RF with an RMSE of 0.489 and XGBoost with an RMSE of 0.488.

The RMSE represents the average difference between the predicted values and the actual values. A value of 0 would indicate a perfect match between predictions and actual values.

Having RMSE values close to each other suggests that both models perform similarly in terms of predictive accuracy. They provide similar levels of accuracy in predicting the target variable.

# **Thank YOU**
"""